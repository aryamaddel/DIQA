{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64e5afc6",
   "metadata": {},
   "source": [
    "## Metrics Computation\n",
    "Compute raw scores using BRISQUE, NIQE, and PIQE via PyIQA (or similar libraries)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1732d5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32.50555419921875\n",
      "3.1774538518950837\n",
      "30.821895599365234\n"
     ]
    }
   ],
   "source": [
    "import pyiqa\n",
    "\n",
    "image = \"koniq10k_1024x768/10325321.jpg\"\n",
    "\n",
    "brisque_metric = pyiqa.create_metric(\"brisque\")\n",
    "niqe_metric = pyiqa.create_metric(\"niqe\")\n",
    "piqe_metric = pyiqa.create_metric(\"piqe\")\n",
    "\n",
    "brisque_score = brisque_metric(image)\n",
    "print(brisque_score.item())\n",
    "\n",
    "niqe_score = niqe_metric(image)\n",
    "print(niqe_score.item())\n",
    "\n",
    "piqe_score = piqe_metric(image)\n",
    "print(piqe_score.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac0361ed",
   "metadata": {},
   "source": [
    "## Refined Out-of-Bounds Check\n",
    "\n",
    "BRISQUE: Theoretically ranges 0–100, where lower is better. Escalate if the score < 0 or > 100 .\n",
    "\n",
    "NIQE: Starts at 0 (best), no strict upper bound. In practice, values for most natural images lie around 3–20. Escalate if score < 0 or > 25.\n",
    "\n",
    "PIQE: Theoretical range is 0–100. Escalate if outside that range (rare in practice).\n",
    "\n",
    "Escalate directly to heavy IQA (MANIQA/HyperIQA) if any score is out-of-bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32219816",
   "metadata": {},
   "outputs": [],
   "source": [
    "if brisque_score.item() < 0 or brisque_score.item() > 100:\n",
    "    print(\"BRISQUE score out of bounds, escalate to deep IQA.\")\n",
    "\n",
    "if niqe_score.item() < 0 or niqe_score.item() > 100:\n",
    "    print(\"NIQE score out of bounds, escalate to deep IQA.\")\n",
    "\n",
    "if piqe_score.item() < 0 or piqe_score.item() > 100:\n",
    "    print(\"PIQE score out of bounds, escalate to deep IQA.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da612832",
   "metadata": {},
   "source": [
    "## Normalization of Metrics\n",
    "If all scores are valid:\n",
    "\n",
    "Normalize into [0, 1]. For example:\n",
    "\n",
    "brisque_norm = (brisque - 0) / 100\n",
    "\n",
    "niqe_norm    = (niqe - 0) / 25\n",
    "\n",
    "piqe_norm    = (piqe - 0) / 100\n",
    "\n",
    "Direction remains: lower normalized value = better quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7eb6ea8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized BRISQUE: 0.3250555419921875\n",
      "Normalized NIQE: 0.12709815407580335\n",
      "Normalized PIQE: 0.30821895599365234\n"
     ]
    }
   ],
   "source": [
    "brisque_norm = brisque_score.item() / 100\n",
    "niqe_norm = niqe_score.item() / 25\n",
    "piqe_norm = piqe_score.item() / 100\n",
    "\n",
    "normalized_scores = [brisque_norm, niqe_norm, piqe_norm]\n",
    "\n",
    "print(\"Normalized BRISQUE:\", brisque_norm)\n",
    "print(\"Normalized NIQE:\", niqe_norm)\n",
    "print(\"Normalized PIQE:\", piqe_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbe9fe24",
   "metadata": {},
   "source": [
    "## Consistency Check\n",
    "\n",
    "Compute a disagreement metric among normalized scores, such as:\n",
    "\n",
    "Variance (e.g. np.var([brisque_norm, niqe_norm, piqe_norm])), or\n",
    "\n",
    "Range (max − min).\n",
    "\n",
    "If disagreement ≤ threshold (e.g., 0.1), output the average normalized score.\n",
    "\n",
    "If > threshold, escalate to a deep IQA model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "69e80d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance: 0.00803059366068095\n",
      "Range: 0.19795738791638415\n",
      "High disagreement detected, escalate to deep IQA model.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "variance = np.var(normalized_scores)\n",
    "score_range = max(normalized_scores) - min(normalized_scores)\n",
    "threshold = 0.1\n",
    "\n",
    "print(\"Variance:\", variance)\n",
    "print(\"Range:\", score_range)\n",
    "\n",
    "if variance <= threshold and score_range <= threshold:\n",
    "    avg_score = np.mean(normalized_scores)\n",
    "    print(\"Average normalized score:\", avg_score)\n",
    "else:\n",
    "    print(\"High disagreement detected, escalate to deep IQA model.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a675f1",
   "metadata": {},
   "source": [
    "## Deep Model Fallback\n",
    "\n",
    "Use a more reliable deep IQA method (MANIQA, HyperIQA, etc.) to get a final MOS-like score when:\n",
    "\n",
    "Any metric is out-of-bounds, or\n",
    "\n",
    "There is high disagreement between the traditional metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "56da9eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model MANIQA from C:\\Users\\aryam\\.cache\\torch\\hub\\pyiqa\\ckpt_koniq10k.pt\n",
      "0.43611273169517517\n",
      "Loading pretrained model HyperNet from C:\\Users\\aryam\\.cache\\torch\\hub\\pyiqa\\HyperIQA-resnet50-koniq10k-c96c41b1.pth\n",
      "0.6475587487220764\n"
     ]
    }
   ],
   "source": [
    "maniqa_metric = pyiqa.create_metric(\"maniqa\")\n",
    "print(maniqa_metric(image).item())\n",
    "\n",
    "hyper_iqa_metric = pyiqa.create_metric(\"hyperiqa\")\n",
    "print(hyper_iqa_metric(image).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f1c47d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
