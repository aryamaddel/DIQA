{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aea9e525",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 10373 images\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from features import extract_features, feature_names\n",
    "\n",
    "image_dir = \"koniq10k_512x384\"\n",
    "image_files = [\n",
    "    os.path.join(image_dir, f)\n",
    "    for f in os.listdir(image_dir)\n",
    "    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "]\n",
    "print(f\"Processing {len(image_files)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7a19864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting features:   0%|          | 0/10373 [00:00<?, ?it/s]d:\\Github\\NR-IQA\\.venv\\Lib\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n",
      "Extracting features:   0%|          | 1/10373 [00:00<18:55,  9.13it/s]d:\\Github\\NR-IQA\\.venv\\Lib\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n",
      "Extracting features:   1%|          | 104/10373 [00:10<17:33,  9.75it/s]\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m img_path \u001b[38;5;129;01min\u001b[39;00m tqdm(image_files, desc=\u001b[33m\"\u001b[39m\u001b[33mExtracting features\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m      3\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m         all_features.append(\u001b[43mextract_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_path\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m      6\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mimg_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\NR-IQA\\features.py:43\u001b[39m, in \u001b[36mextract_features\u001b[39m\u001b[34m(image_path)\u001b[39m\n\u001b[32m     40\u001b[39m features = []\n\u001b[32m     42\u001b[39m \u001b[38;5;66;03m# Basic luminance statistics (3 features)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m flat = gray.flatten()\n\u001b[32m     44\u001b[39m features.extend(\n\u001b[32m     45\u001b[39m     [\n\u001b[32m     46\u001b[39m         np.mean(flat),\n\u001b[32m   (...)\u001b[39m\u001b[32m     49\u001b[39m     ]\n\u001b[32m     50\u001b[39m )\n\u001b[32m     52\u001b[39m \u001b[38;5;66;03m# Color features (2 features)\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Github\\NR-IQA\\.venv\\Lib\\site-packages\\skimage\\feature\\texture.py:392\u001b[39m, in \u001b[36mlocal_binary_pattern\u001b[39m\u001b[34m(image, P, R, method)\u001b[39m\n\u001b[32m    385\u001b[39m     warnings.warn(\n\u001b[32m    386\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mApplying `local_binary_pattern` to floating-point images may \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    387\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgive unexpected results when small numerical differences between \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    388\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33madjacent pixels are present. It is recommended to use this \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    389\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mfunction with images of integer dtype.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    390\u001b[39m     )\n\u001b[32m    391\u001b[39m image = np.ascontiguousarray(image, dtype=np.float64)\n\u001b[32m--> \u001b[39m\u001b[32m392\u001b[39m output = \u001b[43m_local_binary_pattern\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethods\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlower\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    393\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "all_features = []\n",
    "for img_path in tqdm(image_files, desc=\"Extracting features\"):\n",
    "    try:\n",
    "        all_features.append(extract_features(img_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {img_path}: {e}\")\n",
    "\n",
    "df_features = pd.DataFrame(all_features, columns=feature_names)\n",
    "df_features[\"image_path\"] = [os.path.basename(p) for p in image_files]\n",
    "df_features.to_csv(\"features.csv\", index=False)\n",
    "print(f\"Features: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import compute_all_scores\n",
    "\n",
    "compute_all_scores(\"koniq10k_512x384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "\n",
    "df_scores = pd.read_csv(\"iqa_raw_scores.csv\")\n",
    "df_mos = pd.read_csv(\"koniq10k_scores_and_distributions.csv\")\n",
    "df_features = pd.read_csv(\"features.csv\")\n",
    "\n",
    "if \"image_name\" not in df_scores.columns:\n",
    "    df_scores.columns = [\"image_name\"] + list(df_scores.columns[1:])\n",
    "\n",
    "df = df_scores.merge(df_mos[[\"image_name\", \"MOS\"]], on=\"image_name\")\n",
    "df = df.merge(df_features, left_on=\"image_name\", right_on=\"image_path\")\n",
    "\n",
    "iqa_methods = [\"brisque\", \"niqe\", \"piqe\", \"maniqa\", \"hyperiqa\"]\n",
    "mos_predictions = {}\n",
    "regression_coefficients = {}\n",
    "\n",
    "for method in iqa_methods:\n",
    "    reg = LinearRegression()\n",
    "    X = df[[method]].values\n",
    "    y = df[\"MOS\"].values\n",
    "    reg.fit(X, y)\n",
    "    mos_predictions[f\"{method}_mos\"] = reg.predict(X)\n",
    "    regression_coefficients[method] = {\n",
    "        \"coef\": float(reg.coef_[0]),\n",
    "        \"intercept\": float(reg.intercept_),\n",
    "    }\n",
    "    print(f\"{method}: R²={reg.score(X, y):.4f}\")\n",
    "\n",
    "with open(\"mos_mapping_coefficients.json\", \"w\") as f:\n",
    "    json.dump(regression_coefficients, f, indent=2)\n",
    "\n",
    "errors = {\n",
    "    method: np.abs(mos_predictions[f\"{method}_mos\"] - df[\"MOS\"].values)\n",
    "    for method in iqa_methods\n",
    "}\n",
    "errors_df = pd.DataFrame(errors)\n",
    "df[\"best_method\"] = errors_df.idxmin(axis=1)\n",
    "df[\"best_method_label\"] = df[\"best_method\"].map(\n",
    "    {m: i for i, m in enumerate(iqa_methods)}\n",
    ")\n",
    "df[\"best_method_error\"] = errors_df.min(axis=1)\n",
    "\n",
    "print(f\"\\n{df['best_method'].value_counts()}\")\n",
    "df.to_csv(\"router_training_data.csv\", index=False)\n",
    "print(f\"Dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"router_training_data.csv\")\n",
    "X = df[feature_names].values\n",
    "y = df[\"best_method_label\"].values\n",
    "\n",
    "# Train on ALL data (no split - you'll test on separate dataset later)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "router = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "router.fit(X_scaled, y, verbose=50)\n",
    "\n",
    "# Training performance\n",
    "y_pred = router.predict(X_scaled)\n",
    "print(f\"Training Accuracy: {np.mean(y_pred == y):.4f}\")\n",
    "\n",
    "# Confusion matrix on training data\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=iqa_methods,\n",
    "    yticklabels=iqa_methods,\n",
    ")\n",
    "plt.title(\"Confusion Matrix (Training Data)\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Save router and scaler\n",
    "router.save_model(\"router_xgb.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\n✓ Router trained on all data and saved!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62463c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = router.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "for i in range(min(15, len(importance))):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]}: {importance[indices[i]]:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(importance)), importance[indices], color=\"steelblue\")\n",
    "plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame(\n",
    "    {\"Feature\": [feature_names[i] for i in indices], \"Importance\": importance[indices]}\n",
    ").to_csv(\"feature_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960891b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from router import predict\n",
    "\n",
    "# Use same test split for evaluation (even though router trained on all data)\n",
    "df_full = pd.read_csv(\"router_training_data.csv\")\n",
    "_, test_df = train_test_split(\n",
    "    df_full, test_size=0.2, random_state=42, stratify=df_full[\"best_method_label\"]\n",
    ")\n",
    "\n",
    "# Adaptive routing predictions\n",
    "predictions, confidences, selected_methods, times = [], [], [], []\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    try:\n",
    "        result = predict(f\"koniq10k_512x384/{row['image_name']}\")\n",
    "        predictions.append(result[\"MOS_estimate\"])\n",
    "        confidences.append(result[\"confidence\"])\n",
    "        selected_methods.append(result[\"selected_method\"])\n",
    "        times.append(result[\"timing\"][\"total_time_ms\"])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "ground_truth = test_df[\"MOS\"].values[: len(predictions)]\n",
    "\n",
    "# Compute metrics\n",
    "srocc = spearmanr(predictions, ground_truth)[0]\n",
    "plcc = pearsonr(predictions, ground_truth)[0]\n",
    "rmse = np.sqrt(mean_squared_error(ground_truth, predictions))\n",
    "mae = mean_absolute_error(ground_truth, predictions)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"ADAPTIVE ROUTING PERFORMANCE\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"SROCC: {srocc:.4f}\")\n",
    "print(f\"PLCC:  {plcc:.4f}\")\n",
    "print(f\"RMSE:  {rmse:.4f}\")\n",
    "print(f\"MAE:   {mae:.4f}\")\n",
    "print(f\"Avg Time: {np.mean(times):.2f}ms\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Method usage statistics\n",
    "from collections import Counter\n",
    "\n",
    "method_counts = Counter(selected_methods)\n",
    "print(f\"\\nMethod Selection Distribution:\")\n",
    "for method, count in method_counts.most_common():\n",
    "    print(f\"  {method}: {count} ({count/len(selected_methods)*100:.1f}%)\")\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(\n",
    "    ground_truth, predictions, alpha=0.5, s=30, edgecolors=\"black\", linewidths=0.5\n",
    ")\n",
    "plt.plot([1, 5], [1, 5], \"r--\", linewidth=2, label=\"Perfect\")\n",
    "plt.xlabel(\"Ground Truth MOS\")\n",
    "plt.ylabel(\"Predicted MOS\")\n",
    "plt.title(f\"Adaptive Routing\\nSROCC={srocc:.4f}, PLCC={plcc:.4f}, RMSE={rmse:.4f}\")\n",
    "plt.legend()\n",
    "plt.xlim(1, 5)\n",
    "plt.ylim(1, 5)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prediction_scatter.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "# Save detailed results\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"image_name\": test_df[\"image_name\"].values[: len(predictions)],\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"predicted\": predictions,\n",
    "        \"method\": selected_methods,\n",
    "        \"confidence\": confidences,\n",
    "        \"time_ms\": times,\n",
    "        \"error\": np.abs(predictions - ground_truth),\n",
    "    }\n",
    ").to_csv(\"evaluation_results.csv\", index=False)\n",
    "\n",
    "print(\"\\n✓ Evaluation complete! Results saved to 'evaluation_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_image(image_path):\n",
    "    \"\"\"\n",
    "    Quick image quality assessment using deterministic routing.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    result = predict(image_path)\n",
    "\n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"MOS: {result['MOS_estimate']:.3f}/5.0\")\n",
    "    print(\n",
    "        f\"Method: {result['selected_method']} (confidence: {result['confidence']:.3f})\"\n",
    "    )\n",
    "    print(f\"Time: {result['timing']['total_time_ms']:.2f}ms\")\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage\n",
    "r = assess_image(\"me at night.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
