{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from features import extract_features, feature_names\n",
    "\n",
    "image_dir = \"koniq10k_512x384\"\n",
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "print(f\"Processing {len(image_files)} images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = []\n",
    "for img_path in tqdm(image_files, desc=\"Extracting features\"):\n",
    "    try:\n",
    "        all_features.append(extract_features(img_path))\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {img_path}: {e}\")\n",
    "\n",
    "df_features = pd.DataFrame(all_features, columns=feature_names)\n",
    "df_features['image_path'] = [os.path.basename(p) for p in image_files]\n",
    "df_features.to_csv(\"features.csv\", index=False)\n",
    "print(f\"Features: {df_features.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import compute_all_scores\n",
    "compute_all_scores(\"koniq10k_512x384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "\n",
    "df_scores = pd.read_csv(\"iqa_raw_scores.csv\")\n",
    "df_mos = pd.read_csv(\"koniq10k_scores_and_distributions.csv\")\n",
    "df_features = pd.read_csv(\"features.csv\")\n",
    "\n",
    "if 'image_name' not in df_scores.columns:\n",
    "    df_scores.columns = ['image_name'] + list(df_scores.columns[1:])\n",
    "\n",
    "df = df_scores.merge(df_mos[[\"image_name\", \"MOS\"]], on=\"image_name\")\n",
    "df = df.merge(df_features, left_on=\"image_name\", right_on=\"image_path\")\n",
    "\n",
    "iqa_methods = [\"brisque\", \"niqe\", \"piqe\", \"maniqa\", \"hyperiqa\"]\n",
    "mos_predictions = {}\n",
    "regression_coefficients = {}\n",
    "\n",
    "for method in iqa_methods:\n",
    "    reg = LinearRegression()\n",
    "    X = df[[method]].values\n",
    "    y = df[\"MOS\"].values\n",
    "    reg.fit(X, y)\n",
    "    mos_predictions[f\"{method}_mos\"] = reg.predict(X)\n",
    "    regression_coefficients[method] = {'coef': float(reg.coef_[0]), 'intercept': float(reg.intercept_)}\n",
    "    print(f\"{method}: RÂ²={reg.score(X, y):.4f}\")\n",
    "\n",
    "with open(\"mos_mapping_coefficients.json\", \"w\") as f:\n",
    "    json.dump(regression_coefficients, f, indent=2)\n",
    "\n",
    "errors = {method: np.abs(mos_predictions[f\"{method}_mos\"] - df[\"MOS\"].values) for method in iqa_methods}\n",
    "errors_df = pd.DataFrame(errors)\n",
    "df[\"best_method\"] = errors_df.idxmin(axis=1)\n",
    "df[\"best_method_label\"] = df[\"best_method\"].map({m: i for i, m in enumerate(iqa_methods)})\n",
    "df[\"best_method_error\"] = errors_df.min(axis=1)\n",
    "\n",
    "print(f\"\\n{df['best_method'].value_counts()}\")\n",
    "df.to_csv(\"router_training_data.csv\", index=False)\n",
    "print(f\"Dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"router_training_data.csv\")\n",
    "X = df[feature_names].values\n",
    "y = df[\"best_method_label\"].values\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "router = XGBClassifier(n_estimators=200, learning_rate=0.05, max_depth=6, subsample=0.8, \n",
    "                       colsample_bytree=0.8, gamma=0.1, reg_lambda=1.0, reg_alpha=0.1,\n",
    "                       objective=\"multi:softprob\", num_class=5, n_jobs=-1, random_state=42, eval_metric=\"mlogloss\")\n",
    "\n",
    "router.fit(X_train_scaled, y_train, eval_set=[(X_train_scaled, y_train), (X_test_scaled, y_test)], verbose=50)\n",
    "\n",
    "y_pred_proba = router.predict_proba(X_test_scaled)\n",
    "print(f\"Train Acc: {accuracy_score(y_train, router.predict(X_train_scaled)):.4f}\")\n",
    "print(f\"Test Acc: {accuracy_score(y_test, router.predict(X_test_scaled)):.4f}\")\n",
    "print(classification_report(y_test, router.predict(X_test_scaled), target_names=iqa_methods))\n",
    "\n",
    "cm = confusion_matrix(y_test, router.predict(X_test_scaled))\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=iqa_methods, yticklabels=iqa_methods)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.savefig(\"confusion_matrix.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "confidences = np.max(y_pred_proba, axis=1)\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(confidences, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.xlabel('Confidence')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Confidence Distribution')\n",
    "plt.savefig(\"confidence_distribution.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "router.save_model(\"router_xgb.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(f\"Confidence: mean={np.mean(confidences):.4f}, median={np.median(confidences):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62463c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "importance = router.feature_importances_\n",
    "indices = np.argsort(importance)[::-1]\n",
    "\n",
    "for i in range(min(15, len(importance))):\n",
    "    print(f\"{i+1}. {feature_names[indices[i]]}: {importance[indices[i]]:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(range(len(importance)), importance[indices], color='steelblue')\n",
    "plt.xticks(range(len(importance)), [feature_names[i] for i in indices], rotation=90)\n",
    "plt.xlabel(\"Features\")\n",
    "plt.ylabel(\"Importance\")\n",
    "plt.title(\"Feature Importance\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"feature_importance.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({'Feature': [feature_names[i] for i in indices], 'Importance': importance[indices]}).to_csv(\"feature_importance.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960891b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import spearmanr, pearsonr\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from router import predict, mos_mapping\n",
    "\n",
    "df_full = pd.read_csv(\"router_training_data.csv\")\n",
    "_, test_df = train_test_split(df_full, test_size=0.2, random_state=42, stratify=df_full[\"best_method_label\"])\n",
    "\n",
    "predictions, confidences, selected_methods, times = [], [], [], []\n",
    "for idx, row in tqdm(test_df.iterrows(), total=len(test_df)):\n",
    "    try:\n",
    "        result = predict(f\"koniq10k_512x384/{row['image_name']}\", confidence_threshold=0.5)\n",
    "        predictions.append(result['MOS_estimate'])\n",
    "        confidences.append(result['confidence'])\n",
    "        selected_methods.append(result['selected_method'])\n",
    "        times.append(result['timing']['total_time_ms'])\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "ground_truth = test_df['MOS'].values[:len(predictions)]\n",
    "\n",
    "srocc = spearmanr(predictions, ground_truth)[0]\n",
    "plcc = pearsonr(predictions, ground_truth)[0]\n",
    "rmse = np.sqrt(mean_squared_error(ground_truth, predictions))\n",
    "mae = mean_absolute_error(ground_truth, predictions)\n",
    "\n",
    "print(f\"SROCC: {srocc:.4f} | PLCC: {plcc:.4f} | RMSE: {rmse:.4f} | MAE: {mae:.4f} | Time: {np.mean(times):.2f}ms\")\n",
    "\n",
    "baseline_results = {}\n",
    "for method in iqa_methods:\n",
    "    scores = test_df[method].values[:len(predictions)]\n",
    "    method_mos = mos_mapping[method]['coef'] * scores + mos_mapping[method]['intercept']\n",
    "    s = spearmanr(method_mos, ground_truth)[0]\n",
    "    p = pearsonr(method_mos, ground_truth)[0]\n",
    "    r = np.sqrt(mean_squared_error(ground_truth, method_mos))\n",
    "    baseline_results[method] = {'SROCC': s, 'PLCC': p, 'RMSE': r}\n",
    "    print(f\"{method}: SROCC={s:.4f}, PLCC={p:.4f}, RMSE={r:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(ground_truth, predictions, alpha=0.5, s=30, edgecolors='black', linewidths=0.5)\n",
    "plt.plot([1, 5], [1, 5], 'r--', linewidth=2, label='Perfect')\n",
    "plt.xlabel('Ground Truth MOS')\n",
    "plt.ylabel('Predicted MOS')\n",
    "plt.title(f'SROCC={srocc:.4f}, PLCC={plcc:.4f}, RMSE={rmse:.4f}')\n",
    "plt.legend()\n",
    "plt.xlim(1, 5)\n",
    "plt.ylim(1, 5)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"prediction_scatter.png\", dpi=300)\n",
    "plt.show()\n",
    "\n",
    "pd.DataFrame({'image_name': test_df['image_name'].values[:len(predictions)], 'ground_truth': ground_truth, \n",
    "              'predicted': predictions, 'method': selected_methods, 'confidence': confidences,\n",
    "              'time_ms': times, 'error': np.abs(predictions - ground_truth)}).to_csv(\"evaluation_results.csv\", index=False)\n",
    "\n",
    "pd.DataFrame({'Method': ['Adaptive'] + iqa_methods,\n",
    "              'SROCC': [srocc] + [baseline_results[m]['SROCC'] for m in iqa_methods],\n",
    "              'PLCC': [plcc] + [baseline_results[m]['PLCC'] for m in iqa_methods],\n",
    "              'RMSE': [rmse] + [baseline_results[m]['RMSE'] for m in iqa_methods]}).to_csv(\"performance_summary.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
