{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aea9e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from preprocess import preprocess_image\n",
    "from feature_extractor import extract_features, feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f058fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = \"koniq10k_512x384/826373.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1d3e6f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image: koniq10k_512x384/826373.jpg\n",
      "Step 1: Preprocessing image...\n",
      "  ✓ RGB shape: (384, 512, 3)\n",
      "  ✓ Gray shape: (384, 512)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing image: {image_path}\")\n",
    "\n",
    "# Step 1: Preprocess (standardize the image)\n",
    "print(\"Step 1: Preprocessing image...\")\n",
    "preprocessed = preprocess_image(image_path)\n",
    "print(f\"  ✓ RGB shape: {preprocessed['rgb'].shape}\")\n",
    "print(f\"  ✓ Gray shape: {preprocessed['gray'].shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a19864a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 2: Extracting features...\n",
      "  ✓ Extracted 19 features\n",
      "Features extracted: 19\n",
      "\n",
      "Feature Summary:\n",
      "------------------------------\n",
      "mean_luminance      : 0.392189\n",
      "std_luminance       : 0.236095\n",
      "skewness_luminance  : -0.028520\n",
      "kurtosis_luminance  : -0.696999\n",
      "entropy_luminance   : 7.624218\n",
      "median_luminance    : 0.415686\n",
      "colorfulness        : 0.317180\n",
      "mean_saturation     : 0.743218\n",
      "laplacian_variance  : 6119.246582\n",
      "tenengrad           : 125.270241\n",
      "canny_edge_ratio    : 0.306412\n",
      "lbp_uniformity      : 2.336101\n",
      "noise_std_estimate  : 0.055541\n",
      "blockiness_energy   : 0.000262\n",
      "rms_contrast        : 0.236095\n",
      "percentile_contrast : 0.658824\n",
      "low_freq_energy     : 0.233426\n",
      "mid_freq_energy     : 0.063730\n",
      "high_freq_energy    : 0.029758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\NR-IQA\\.venv\\Lib\\site-packages\\skimage\\feature\\texture.py:385: UserWarning: Applying `local_binary_pattern` to floating-point images may give unexpected results when small numerical differences between adjacent pixels are present. It is recommended to use this function with images of integer dtype.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Extract features (from the standardized image)\n",
    "print(\"Step 2: Extracting features...\")\n",
    "features = extract_features(preprocessed)\n",
    "print(f\"  ✓ Extracted {len(features)} features\")\n",
    "\n",
    "print(f\"Features extracted: {len(features)}\")\n",
    "\n",
    "print(\"\\nFeature Summary:\")\n",
    "print(\"-\" * 30)\n",
    "for name, value in zip(feature_names, features):\n",
    "    print(f\"{name:20s}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e34b1209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\NR-IQA\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Step 3: Computing IQA scores...\n",
      "Loaded brisque\n",
      "Loaded niqe\n",
      "Loaded piqe\n",
      "Loaded maniqa\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\Documents\\GitHub\\NR-IQA\\.venv\\Lib\\site-packages\\timm\\models\\layers\\__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n",
      "  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained model MANIQA from C:\\Users\\user\\.cache\\torch\\hub\\pyiqa\\ckpt_koniq10k.pt\n",
      "Loaded hyperiqa\n",
      "Loading pretrained model HyperNet from C:\\Users\\user\\.cache\\torch\\hub\\pyiqa\\HyperIQA-resnet50-koniq10k-c96c41b1.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing IQA scores: 100%|██████████| 10373/10373 [1:45:49<00:00,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved raw scores to iqa_raw_scores.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Step3 Compute outputs from every IQA model\n",
    "from iqa_scorers import compute_all_scores\n",
    "\n",
    "print(\"\\nStep 3: Computing IQA scores...\")\n",
    "compute_all_scores(\"koniq10k_512x384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c4bd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
