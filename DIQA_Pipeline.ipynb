{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aea9e525",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "image_dir = \"koniq10k_512x384\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a19864a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract simplified features (only 6 key features)\n",
    "from features import build_features, feature_names\n",
    "\n",
    "print(\"Extracting simplified features:\", feature_names)\n",
    "df_features = build_features(image_dir, out_csv=\"features.csv\")\n",
    "print(f\"Features extracted: {df_features.shape}\")\n",
    "print(\"\\nFirst few rows:\")\n",
    "print(df_features.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac18861",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display feature statistics\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.ravel()\n",
    "\n",
    "for i, feature in enumerate(feature_names):\n",
    "    axes[i].hist(df_features[feature], bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "    axes[i].set_title(f'{feature.replace(\"_\", \" \").title()}')\n",
    "    axes[i].set_xlabel(\"Value\")\n",
    "    axes[i].set_ylabel(\"Frequency\")\n",
    "    axes[i].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Summary Statistics:\")\n",
    "print(df_features[feature_names].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34b1209",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scoring import compute_all_scores\n",
    "\n",
    "compute_all_scores(\"koniq10k_512x384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2de9ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MOS mapping models per IQA method and prepare router training dataset\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import json\n",
    "\n",
    "df_scores = pd.read_csv(\"iqa_raw_scores.csv\")\n",
    "df_mos = pd.read_csv(\"koniq10k_scores_and_distributions.csv\")\n",
    "df_features = pd.read_csv(\"features.csv\")\n",
    "\n",
    "if \"image_name\" not in df_scores.columns:\n",
    "    df_scores.columns = [\"image_name\"] + list(df_scores.columns[1:])\n",
    "\n",
    "df = df_scores.merge(df_mos[[\"image_name\", \"MOS\"]], on=\"image_name\")\n",
    "df = df.merge(df_features, left_on=\"image_name\", right_on=\"image_path\")\n",
    "\n",
    "iqa_methods = [\"brisque\", \"niqe\", \"piqe\", \"maniqa\", \"hyperiqa\"]\n",
    "mos_predictions = {}\n",
    "regression_coefficients = {}\n",
    "\n",
    "for method in iqa_methods:\n",
    "    reg = LinearRegression()\n",
    "    X = df[[method]].values\n",
    "    y = df[\"MOS\"].values\n",
    "    reg.fit(X, y)\n",
    "    mos_predictions[f\"{method}_mos\"] = reg.predict(X)\n",
    "    regression_coefficients[method] = {\n",
    "        \"coef\": float(reg.coef_[0]),\n",
    "        \"intercept\": float(reg.intercept_),\n",
    "    }\n",
    "    print(f\"{method}: R²={reg.score(X, y):.4f}\")\n",
    "\n",
    "with open(\"mos_mapping_coefficients.json\", \"w\") as f:\n",
    "    json.dump(regression_coefficients, f, indent=2)\n",
    "\n",
    "errors = {\n",
    "    method: np.abs(mos_predictions[f\"{method}_mos\"] - df[\"MOS\"].values)\n",
    "    for method in iqa_methods\n",
    "}\n",
    "errors_df = pd.DataFrame(errors)\n",
    "df[\"best_method\"] = errors_df.idxmin(axis=1)\n",
    "df[\"best_method_label\"] = df[\"best_method\"].map(\n",
    "    {m: i for i, m in enumerate(iqa_methods)}\n",
    ")\n",
    "df[\"best_method_error\"] = errors_df.min(axis=1)\n",
    "\n",
    "print(f\"\\n{df['best_method'].value_counts()}\")\n",
    "df.to_csv(\"router_training_data.csv\", index=False)\n",
    "print(f\"Dataset: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39b4c4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train router using simplified features\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import joblib\n",
    "\n",
    "df = pd.read_csv(\"router_training_data.csv\")\n",
    "print(f\"Training with simplified features: {feature_names}\")\n",
    "\n",
    "# Use only the 6 simplified features\n",
    "X = df[feature_names].values\n",
    "y = df[\"best_method_label\"].values\n",
    "\n",
    "print(f\"Training data shape: {X.shape}\")\n",
    "print(f\"Feature names: {feature_names}\")\n",
    "\n",
    "# Train on ALL data (no split - you'll test on separate dataset later)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "router = XGBClassifier(n_estimators=100, random_state=42)\n",
    "router.fit(X_scaled, y, verbose=50)\n",
    "\n",
    "# Training performance\n",
    "y_pred = router.predict(X_scaled)\n",
    "print(f\"Training Accuracy: {np.mean(y_pred == y):.4f}\")\n",
    "\n",
    "# Confusion matrix on training data\n",
    "cm = confusion_matrix(y, y_pred)\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=iqa_methods,\n",
    "    yticklabels=iqa_methods,\n",
    ")\n",
    "plt.title(\"Confusion Matrix (Training Data) - Simplified Features\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n",
    "\n",
    "# Save router and scaler\n",
    "router.save_model(\"router_xgb.json\")\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "print(\"\\n✓ Router trained with simplified features and saved!\")\n",
    "\n",
    "# Display feature importance\n",
    "feature_importance = router.feature_importances_\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(feature_names, feature_importance)\n",
    "plt.title(\"Feature Importance in Router Model\")\n",
    "plt.xlabel(\"Importance\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "for i, (feature, importance) in enumerate(zip(feature_names, feature_importance)):\n",
    "    print(f\"{i+1}. {feature.replace('_', ' ').title()}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "960891b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIVE In-the-Wild testing\n",
    "from scipy.stats import spearmanr, pearsonr\n",
    "from scipy.io import loadmat\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from tqdm import tqdm\n",
    "from router import predict\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from pathlib import Path\n",
    "\n",
    "# Load LIVE In-the-Wild MOS scores from .mat files\n",
    "print(\"Loading LIVE In-the-Wild dataset...\")\n",
    "mos_data = loadmat(\"Data/AllMOS_release.mat\")\n",
    "images_data = loadmat(\"Data/AllImages_release.mat\")\n",
    "\n",
    "# Extract image names and MOS scores\n",
    "# The structure might vary, so we'll handle common formats\n",
    "if 'AllMOS_release' in mos_data:\n",
    "    mos_scores = mos_data['AllMOS_release'].flatten()\n",
    "elif 'MOS' in mos_data:\n",
    "    mos_scores = mos_data['MOS'].flatten()\n",
    "else:\n",
    "    # Print available keys to help debug\n",
    "    print(\"Available keys in MOS file:\", mos_data.keys())\n",
    "    mos_scores = list(mos_data.values())[3].flatten()  # Skip __header__, __version__, __globals__\n",
    "\n",
    "if 'AllImages_release' in images_data:\n",
    "    image_names = [str(img[0]) for img in images_data['AllImages_release'].flatten()]\n",
    "elif 'images' in images_data:\n",
    "    image_names = [str(img[0]) for img in images_data['images'].flatten()]\n",
    "else:\n",
    "    print(\"Available keys in Images file:\", images_data.keys())\n",
    "    image_names = [str(img[0]) for img in list(images_data.values())[3].flatten()]\n",
    "\n",
    "# Create DataFrame\n",
    "live_mos_df = pd.DataFrame({\n",
    "    'image_name': image_names,\n",
    "    'MOS': mos_scores\n",
    "})\n",
    "\n",
    "print(f\"Loaded {len(live_mos_df)} image records from .mat files\")\n",
    "\n",
    "# Get only images from the Images folder (not trainingImages)\n",
    "live_image_dir = \"Images\"\n",
    "available_images = [\n",
    "    f.name\n",
    "    for f in Path(live_image_dir).iterdir()\n",
    "    if f.suffix.lower() == \".bmp\" and f.is_file()\n",
    "]\n",
    "\n",
    "print(f\"Found {len(available_images)} BMP images in Images folder\")\n",
    "\n",
    "# Filter MOS data to only available images\n",
    "live_mos_df = live_mos_df[live_mos_df[\"image_name\"].isin(available_images)]\n",
    "\n",
    "print(f\"\\nTesting on {len(live_mos_df)} LIVE In-the-Wild images\")\n",
    "print(f\"MOS range: [{live_mos_df['MOS'].min():.2f}, {live_mos_df['MOS'].max():.2f}]\")\n",
    "\n",
    "# Adaptive routing predictions on LIVE dataset\n",
    "predictions, confidences, selected_methods, times = [], [], [], []\n",
    "valid_indices = []\n",
    "\n",
    "for idx, row in tqdm(\n",
    "    live_mos_df.iterrows(), total=len(live_mos_df), desc=\"Testing LIVE\"\n",
    "):\n",
    "    image_path = f\"{live_image_dir}/{row['image_name']}\"\n",
    "\n",
    "    try:\n",
    "        result = predict(image_path)\n",
    "        predictions.append(result[\"MOS_estimate\"])\n",
    "        confidences.append(result[\"confidence\"])\n",
    "        selected_methods.append(result[\"selected_method\"])\n",
    "        times.append(result[\"timing\"][\"total_time_ms\"])\n",
    "        valid_indices.append(idx)\n",
    "    except Exception as e:\n",
    "        print(f\"Error on {row['image_name']}: {e}\")\n",
    "\n",
    "ground_truth = live_mos_df.loc[valid_indices, \"MOS\"].values\n",
    "\n",
    "# Compute metrics\n",
    "srocc = spearmanr(predictions, ground_truth)[0]\n",
    "plcc = pearsonr(predictions, ground_truth)[0]\n",
    "rmse = np.sqrt(mean_squared_error(ground_truth, predictions))\n",
    "mae = mean_absolute_error(ground_truth, predictions)\n",
    "\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"LIVE IN-THE-WILD CROSS-DATASET TEST\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Trained on: KonIQ-10k\")\n",
    "print(f\"Tested on: LIVE In-the-Wild ({len(predictions)} images)\")\n",
    "print(f\"SROCC: {srocc:.4f}\")\n",
    "print(f\"PLCC:  {plcc:.4f}\")\n",
    "print(f\"RMSE:  {rmse:.4f}\")\n",
    "print(f\"MAE:   {mae:.4f}\")\n",
    "print(f\"Avg Time: {np.mean(times):.2f}ms\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "# Method usage statistics\n",
    "method_counts = Counter(selected_methods)\n",
    "print(f\"\\nMethod Selection Distribution:\")\n",
    "for method, count in method_counts.most_common():\n",
    "    print(f\"  {method}: {count} ({count/len(selected_methods)*100:.1f}%)\")\n",
    "\n",
    "# Scatter plot\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.scatter(\n",
    "    ground_truth, predictions, alpha=0.5, s=30, edgecolors=\"black\", linewidths=0.5\n",
    ")\n",
    "plt.plot(\n",
    "    [ground_truth.min(), ground_truth.max()],\n",
    "    [ground_truth.min(), ground_truth.max()],\n",
    "    \"r--\",\n",
    "    linewidth=2,\n",
    "    label=\"Perfect\",\n",
    ")\n",
    "plt.xlabel(\"Ground Truth MOS (LIVE)\")\n",
    "plt.ylabel(\"Predicted MOS (KonIQ-10k trained)\")\n",
    "plt.title(\n",
    "    f\"Cross-Dataset Test: KonIQ-10k → LIVE In-the-Wild\\n\"\n",
    "    f\"SROCC={srocc:.4f}, PLCC={plcc:.4f}, RMSE={rmse:.4f}\"\n",
    ")\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"live_cross_dataset_results.png\", dpi=150)\n",
    "plt.show()\n",
    "\n",
    "# Save detailed results\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"image_name\": live_mos_df.loc[valid_indices, \"image_name\"].values,\n",
    "        \"ground_truth\": ground_truth,\n",
    "        \"predicted\": predictions,\n",
    "        \"method\": selected_methods,\n",
    "        \"confidence\": confidences,\n",
    "        \"time_ms\": times,\n",
    "        \"error\": np.abs(predictions - ground_truth),\n",
    "    }\n",
    ").to_csv(\"live_test_results.csv\", index=False)\n",
    "\n",
    "print(\"\\n✓ Cross-dataset evaluation complete! Results saved to 'live_test_results.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be48dcd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assess_image(image_path):\n",
    "    \"\"\"\n",
    "    Quick image quality assessment using simplified features and adaptive routing.\n",
    "    Uses only 6 key features: brightness, contrast, colorfulness, sharpness, saturation, texture/noise.\n",
    "    \"\"\"\n",
    "    if not os.path.isfile(image_path):\n",
    "        raise FileNotFoundError(f\"Image not found: {image_path}\")\n",
    "\n",
    "    result = predict(image_path)\n",
    "\n",
    "    print(f\"Image: {os.path.basename(image_path)}\")\n",
    "    print(f\"MOS: {result['MOS_estimate']:.3f}/5.0\")\n",
    "    print(\n",
    "        f\"Method: {result['selected_method']} (confidence: {result['confidence']:.3f})\"\n",
    "    )\n",
    "    print(f\"Time: {result['timing']['total_time_ms']:.2f}ms\")\n",
    "\n",
    "    # Show the extracted features for this image\n",
    "    from features import extract_features\n",
    "\n",
    "    features = extract_features(image_path)\n",
    "    print(f\"\\nExtracted Features:\")\n",
    "    for i, (name, value) in enumerate(zip(feature_names, features)):\n",
    "        print(f\"  {i+1}. {name.replace('_', ' ').title()}: {value:.4f}\")\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "# Example usage with the simplified feature set\n",
    "print(\"=== Simplified NR-IQA Assessment ===\")\n",
    "print(f\"Using {len(feature_names)} simplified features: {', '.join(feature_names)}\")\n",
    "print()\n",
    "r = assess_image(\"me at night.jpg\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
